{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elQQyE0L5o2K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBFa5YXTvPov"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "global dataset\n",
    "global model\n",
    "global current_class\n",
    "global trf_cont\n",
    "global tau\n",
    "global eps_thresh\n",
    "global lambda_reg\n",
    "global upper_bound_cont\n",
    "global steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IvYlA6orlZYq"
   },
   "outputs": [],
   "source": [
    "# Compute the error between the prediction of a plain image and the prediction of a transformed image\n",
    "# - model: the CNN trained on pure data\n",
    "# - dataset: the dataset of images to use for the optimization\n",
    "# - cls: the class of the images to use for the optimization\n",
    "# - trf_cont: the transformation to apply\n",
    "# - phi: the argument of the transformation\n",
    "def compute_delta_cont(phi):\n",
    "    steps_no = 0\n",
    "    error_sum = 0\n",
    "\n",
    "    # Generate a vector of \"steps\" integer from 0 to len(dataset['data'])\n",
    "    rnd_indexes = np.random.randint(0, len(dataset['data']), steps)\n",
    "\n",
    "    predictions = 0\n",
    "    misclassification = 0\n",
    "\n",
    "    for i in rnd_indexes:\n",
    "\n",
    "        while(dataset['labels'][i] != cls and i < len(dataset['data'])):\n",
    "            i += 1\n",
    "        image = dataset['data'][i]\n",
    "        image = np.array(tf.image.resize(image, (224, 224)).numpy().astype(int))\n",
    "\n",
    "        steps_no += 1\n",
    "        if trf_cont == 'rotate':\n",
    "            transformed_image1 = ((tf.keras.layers.RandomRotation((0.9*phi, phi))(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomRotation((-0.9*phi, 0))(image)).numpy()).astype(int)\n",
    "\n",
    "        elif trf_cont == 'shear':\n",
    "            transformed_image1 = tf.keras.preprocessing.image.random_shear(image, phi, row_axis=0, col_axis=1, channel_axis=2)\n",
    "            transformed_image2 = tf.keras.preprocessing.image.random_shear(image, -phi, row_axis=0, col_axis=1, channel_axis=2)\n",
    "\n",
    "        elif trf_cont == 'horizontal_shift':\n",
    "            transformed_image1 = ((tf.keras.layers.RandomTranslation((0.9*phi, phi), 0)(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomTranslation((-phi, -0.9*phi), 0)(image)).numpy()).astype(int)\n",
    "\n",
    "        elif trf_cont == 'vertical_shift':\n",
    "            transformed_image1 = ((tf.keras.layers.RandomTranslation(0, (0.9*phi, phi))(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomTranslation(0, (-phi, -0.9*phi))(image)).numpy()).astype(int)\n",
    "\n",
    "        elif trf_cont == 'zoom':\n",
    "            transformed_image1 = ((tf.keras.layers.RandomZoom((0.9*phi, phi))(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomZoom((-phi, -0.9*phi))(image)).numpy()).astype(int)\n",
    "\n",
    "        # Optimization to find the optimal upper bound for brightness transformation\n",
    "        elif trf_cont == 'brightness_top':    \n",
    "            transformed_image1 = ((tf.keras.layers.RandomBrightness((0.9*phi, phi))(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomBrightness((0.9*phi, phi))(image)).numpy()).astype(int)\n",
    "\n",
    "        # Optimization to find the optimal lower bound for brightness transformation\n",
    "        elif trf_cont == 'brightness_down':   \n",
    "            transformed_image1 = ((tf.keras.layers.RandomBrightness((-phi, -0.9*phi))(image)).numpy()).astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomBrightness((-phi, -0.9*phi))(image)).numpy()).astype(int)\n",
    "        \n",
    "        elif trf_cont == 'contrast': \n",
    "            transformed_image1 = ((tf.keras.layers.RandomContrast(phi,phi))(image)).numpy().astype(int)\n",
    "            transformed_image2 = ((tf.keras.layers.RandomContrast(phi,phi))(image)).numpy().astype(int)\n",
    "\n",
    "        else:\n",
    "            print('Transformation not found.')\n",
    "            transformed_image1 = transformed_image2 = image\n",
    "\n",
    "        if cls == 'healthy':\n",
    "            prediction1 = model.predict(np.expand_dims(transformed_image1, axis=0))[0]\n",
    "            prediction2 = model.predict(np.expand_dims(transformed_image2, axis=0))[0]\n",
    "\n",
    "            # Compute the statistics\n",
    "            # Checks if the prediction is wrong\n",
    "            if 0 != np.argmax(prediction1):\n",
    "                  misclassification += 1\n",
    "            if 0 != np.argmax(prediction2):\n",
    "                  misclassification += 1\n",
    "\n",
    "            prediction1 = prediction1[0]\n",
    "            prediction2 = prediction2[0]\n",
    "\n",
    "        else:\n",
    "            prediction1 = model.predict(np.expand_dims(transformed_image1, axis=0))[0]\n",
    "            prediction2 = model.predict(np.expand_dims(transformed_image2, axis=0))[0]\n",
    "\n",
    "            # Compute the statistics\n",
    "            # Checks if the prediction is wrong\n",
    "            if 1 != np.argmax(prediction1):\n",
    "                  misclassification += 1\n",
    "            if 1 != np.argmax(prediction2):\n",
    "                  misclassification += 1\n",
    "\n",
    "            prediction1 = prediction1[1]\n",
    "            prediction2 = prediction2[1]\n",
    "\n",
    "        # Compute the error value\n",
    "        error_sum += (abs(1 - prediction1) + abs(1 - prediction2))\n",
    "        predictions += 2\n",
    "\n",
    "        # Stop the search after a fied number of steps\n",
    "        if steps_no == steps:\n",
    "              break\n",
    "\n",
    "    mispredictions_ratio = misclassification/predictions\n",
    "\n",
    "    predictions = 0\n",
    "    misclassification = 0\n",
    "\n",
    "    f = open(\"predictions.txt\", \"a\")\n",
    "    f.write(\"Class \" + cls + \" - Transformation \" + trf_cont + \", misprediction ratio \" +\n",
    "            str(mispredictions_ratio) + \" with phi \" + str(phi) + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    # Error between the prediction with the pure image and the prediction with the transformed image\n",
    "    delta = (1 / (2 * steps_no)) * error_sum\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_oRALh45v5d"
   },
   "outputs": [],
   "source": [
    "# Define the objective function for our optimization problem (funtions with continuous parameters)\n",
    "# - phi: the argument of the transformation (parameter to be optimized)\n",
    "# - dataset: the dataset to use for the optimization\n",
    "# - trf_cont: the transformation to apply\n",
    "# - model: the CNN trained on pure data\n",
    "# - eps_thresh: the threshold for the softmax output\n",
    "# - lambda_reg: balancing coefficient\n",
    "# - upper_bound: the upper bound for the transformation\n",
    "def ObjectiveFunction_cont(phi):\n",
    "    # Get and sum the errors between the plain image and the transformed image\n",
    "    delta = compute_delta_cont(phi)\n",
    "    return min((eps_thresh - delta), 0) + lambda_reg * phi / upper_bound_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15kpc2hO50EN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.array_ops import upper_bound\n",
    "# Optimization based on paper \"Class-Adaptive_Data_Augmentation_for_Image_Classification\"\n",
    "def AugmentationOptimizer(model_CNN, data, steps_no,  eps_thresh_value, lambda_reg_value):\n",
    "\n",
    "    # Golbal variables\n",
    "    global dataset\n",
    "    dataset = data\n",
    "    global model\n",
    "    model = model_CNN\n",
    "    global steps\n",
    "    steps = steps_no\n",
    "\n",
    "    # Create a vector with data transformations:\n",
    "    # - up to gaussian noise, the values are in the range [x, y]\n",
    "    transformations = {'rotate': [0, 0.5], 'shear': [0, 45], 'horizontal_shift': [0, 0.5], 'vertical_shift': [0, 0.5],\n",
    "                       'zoom': [0, 0.5], 'brightness_top': [0, 1], 'brightness_down': [-1, 0], 'contrast': [0, 1]}\n",
    "\n",
    "    # For each class\n",
    "    print('Optimizing...')\n",
    "    global eps_thresh\n",
    "    eps_thresh =  eps_thresh_value\n",
    "    global lambda_reg\n",
    "    lambda_reg = lambda_reg_value\n",
    "    for current_class in ['unhealthy']:\n",
    "        global cls\n",
    "        cls = current_class\n",
    "        \n",
    "        for transformation in transformations.keys():\n",
    "            print(\"Optimizing continue transformations...\")\n",
    "            # Assign the global varables to be seen by the objective function\n",
    "            global trf_cont\n",
    "            trf_cont = transformation\n",
    "            global upper_bound_cont\n",
    "            upper_bound_cont = transformations[trf_cont][1]\n",
    "\n",
    "            print('Class ' + cls + ' - Transformation ' + trf_cont)\n",
    "            print('Bounds: ' + str(transformations[trf_cont][0]) + ' - ' + str(transformations[trf_cont][1]))\n",
    "\n",
    "            # Define space for the parameters\n",
    "            pbounds = {'phi' : (transformations[trf_cont][0], transformations[trf_cont][1])}\n",
    "            # Initialize BayesianOptimization object\n",
    "            optimizer = BayesianOptimization(\n",
    "                f=ObjectiveFunction_cont,\n",
    "                pbounds=pbounds,\n",
    "                verbose=2,\n",
    "                allow_duplicate_points=True\n",
    "            )\n",
    "\n",
    "            # Define the type of optimization\n",
    "            optimizer.maximize(init_points=5,n_iter=10)\n",
    "\n",
    "            # Retrieve the results\n",
    "            optimal_params = optimizer.max['params']\n",
    "            optimal_objective_value = optimizer.max['target']\n",
    "\n",
    "            print(\"Optimal phi for \" + str(trf_cont) + \" for \" + cls + \" class: \" + str(optimal_params))\n",
    "            print(\"Optimal objective function value for \" + str(trf_cont) + \": \" + str(optimal_objective_value))\n",
    "\n",
    "\n",
    "            # Save the results into a file\n",
    "            f = open(\"results.txt\", \"a\")\n",
    "            f.write(\"Class \" + cls + \" - Transformation \" + trf_cont + \": \" + str(optimal_params) + \"\\n\")\n",
    "            f.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPhWo9RsrZpj",
    "outputId": "54d9a807-8476-48b0-dcff-c5ac58289b02"
   },
   "outputs": [],
   "source": [
    "# From typing_extensions import dataclass_transform\n",
    "print('Loading model...')\n",
    "model_CNN = tf.keras.models.load_model(\"ConvNeXtLarge_lr_0.001_bs_64_val_0.9185779690742493\")\n",
    "data = np.load(\"train_dataset_no_duplicate.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrClFYgH54QO",
    "outputId": "4a78d5a3-e350-463c-9e80-fb1e83e350d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the optimizer\n",
    "steps_no = 20 # Number of images used for each iteration\n",
    "eps_thresh_value = 0.1 # Values suggested by the creators of the method\n",
    "lambda_reg_value = 0.01\n",
    "AugmentationOptimizer(model_CNN, data, steps_no, eps_thresh_value, lambda_reg_value)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
